{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import argparse\n",
    "from tqdm import tqdm  # For displaying progress bars during training\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.manifold import TSNE  # For visualizing decision boundaries\n",
    "\n",
    "# Check if running in a Jupyter notebook environment\n",
    "if 'ipykernel' in sys.modules:\n",
    "    debug = False\n",
    "else:\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-d\", \"--debug\", action='store_true', help=\"Debug mode\")\n",
    "    args = ap.parse_args()\n",
    "    debug = args.debug\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Hyperparameters\n",
    "val_split = 0.1             # Fraction of data to be used for validation\n",
    "unlabelled_size = 0.99      # Fraction of the training data to be initially unlabelled\n",
    "lr = 0.0005                 # Learning rate for the optimizer\n",
    "batch_size = 64             # Batch size for training and validation\n",
    "num_epochs = 100            # Number of epochs for each training phase\n",
    "label_iterations = 2        # Number of iterations of active learning or random sampling\n",
    "top_frac = 0.01             # Fraction of uncertain samples selected in each active learning iteration\n",
    "\n",
    "### Setting up the MNIST dataset\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "if debug:\n",
    "    train_dataset.data = train_dataset.data[:1000]\n",
    "    train_dataset.targets = train_dataset.targets[:1000]\n",
    "    torch.set_num_threads(4)\n",
    "\n",
    "val_dataset = deepcopy(train_dataset)\n",
    "train_size = int((1 - val_split) * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "indexes = torch.randperm(len(train_dataset)).tolist()\n",
    "\n",
    "indexes_val = indexes[train_size:]\n",
    "val_dataset.targets = val_dataset.targets[indexes_val]\n",
    "val_dataset.data = val_dataset.data[indexes_val]\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "indexes_train = indexes[:train_size]\n",
    "train_dataset.targets = train_dataset.targets[indexes_train]\n",
    "train_dataset.data = train_dataset.data[indexes_train]\n",
    "\n",
    "unlabelled_size = int(unlabelled_size * len(train_dataset))\n",
    "indexes_train = torch.randperm(len(train_dataset)).tolist()\n",
    "unlabelled_dataset = deepcopy(train_dataset)\n",
    "unlabelled_dataset.targets = unlabelled_dataset.targets[indexes_train[:unlabelled_size]]\n",
    "unlabelled_dataset.data = unlabelled_dataset.data[indexes_train[:unlabelled_size]]\n",
    "train_dataset.targets = train_dataset.targets[indexes_train[unlabelled_size:]]\n",
    "train_dataset.data = train_dataset.data[indexes_train[unlabelled_size:]]\n",
    "start_train_dataset = deepcopy(train_dataset)\n",
    "start_unlabelled_dataset = deepcopy(unlabelled_dataset)\n",
    "\n",
    "print(f\"Initial labeled images in training set: {len(train_dataset)}\")\n",
    "print(f\"Initial unlabeled images in unlabeled set: {len(unlabelled_dataset)}\")\n",
    "\n",
    "\n",
    "# Function to transfer data from the unlabelled dataset to the labelled dataset\n",
    "def transfer_unlabelled_to_labelled(unlabelled_dataset, train_dataset, indexes, uncertainties=None):\n",
    "    # If uncertainties are provided, sort indexes by uncertainty\n",
    "    if uncertainties is not None:\n",
    "        # Sort indexes by uncertainty, selecting the top uncertain samples (up to 25)\n",
    "        sorted_indexes = [idx for _, idx in sorted(zip(uncertainties, indexes), reverse=True)]\n",
    "        selected_indexes = sorted_indexes[:25]  # Top uncertain samples, max 25\n",
    "    else:\n",
    "        # If no uncertainties are provided (random sampling), use indexes directly\n",
    "        selected_indexes = indexes[:25] if len(indexes) > 25 else indexes\n",
    "    # Convert list of selected indices to a boolean mask for efficient filtering\n",
    "    mask = torch.tensor([i in selected_indexes for i in range(len(unlabelled_dataset.targets))])\n",
    "    # Save selected images and labels before modifying unlabelled_dataset\n",
    "    selected_images = unlabelled_dataset.data[mask]\n",
    "    selected_labels = unlabelled_dataset.targets[mask]\n",
    "    # Add selected unlabelled samples to the labelled training dataset\n",
    "    train_dataset.targets = torch.cat([train_dataset.targets, selected_labels])\n",
    "    train_dataset.data = torch.cat([train_dataset.data, selected_images])\n",
    "    # Remove the added samples from the unlabelled dataset\n",
    "    unlabelled_dataset.targets = unlabelled_dataset.targets[~mask]\n",
    "    unlabelled_dataset.data = unlabelled_dataset.data[~mask]\n",
    "    # Display added images for \"eye test\"\n",
    "    display_added_images(selected_images, selected_labels)\n",
    "    return train_dataset, unlabelled_dataset\n",
    "\n",
    "\n",
    "# Function to display added images\n",
    "def display_added_images(images, labels):\n",
    "    # Convert images to float and normalize before displaying\n",
    "    images = images.float() / 255.0  # Convert to Float and scale to [0, 1]\n",
    "    num_images = min(25, len(images))  # Display up to 25 images\n",
    "    grid_size = int(np.ceil(np.sqrt(num_images)))  # Define grid size based on number of images\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(12, 10))\n",
    "    fig.suptitle(\"Top Uncertain Newly Added Images in Active Learning\")\n",
    "    # Loop over grid and display each image if available\n",
    "    for i in range(grid_size * grid_size):\n",
    "        ax = axes[i // grid_size, i % grid_size]\n",
    "        if i < num_images:\n",
    "            image, label = images[i], labels[i]\n",
    "            ax.imshow(image.numpy().squeeze(), cmap='gray')\n",
    "            ax.set_title(f\"Label: {label}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "# Function to visualize decision boundaries using t-SNE with a subset of data\n",
    "def visualize_decision_boundaries(model, unlabelled_dataset, device, sample_size=500):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    # Use a subset of unlabelled data if the dataset is large\n",
    "    subset_indices = torch.randperm(len(unlabelled_dataset))[:sample_size]\n",
    "    subset_data = unlabelled_dataset.data[subset_indices]\n",
    "    subset_targets = unlabelled_dataset.targets[subset_indices]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in zip(subset_data, subset_targets):\n",
    "            image = image.float().unsqueeze(0).unsqueeze(0).to(device) / 255.0  # Normalize and add batch dimension\n",
    "            embedding = model(image).cpu().numpy()\n",
    "            embeddings.append(embedding)\n",
    "            labels.append(label)\n",
    "\n",
    "    # Run t-SNE for dimensionality reduction\n",
    "    embeddings = np.array(embeddings).reshape(len(subset_data), -1)\n",
    "    tsne = TSNE(n_components=2)\n",
    "    tsne_results = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Plot the t-SNE results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels, cmap='tab10')\n",
    "    plt.legend(handles=scatter.legend_elements()[0], labels=range(10), title=\"Digits\")\n",
    "    plt.title(\"t-SNE of Decision Boundaries in Unlabelled Dataset\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.resnet18(weights=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model_parameters = deepcopy(model.state_dict())\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10, val_interval=1, description=\"\"):\n",
    "    accuracies = []\n",
    "    print(f\"Starting training: {description}\")\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            val_accuracy = validate_model(model, val_loader, device)\n",
    "            accuracies.append(val_accuracy)\n",
    "            print(f'Epoch {epoch + 1}, {description} Accuracy: {val_accuracy:.2f}%')\n",
    "    return accuracies\n",
    "\n",
    "def label_iteration(model, train_dataset, unlabelled_dataset, device, top_frac=top_frac):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    unlabelled_loader = torch.utils.data.DataLoader(unlabelled_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    # Collect predictions for uncertainty\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(unlabelled_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).softmax(dim=1)\n",
    "            predictions.extend(outputs.detach().cpu().numpy())\n",
    "    predictions = torch.tensor(predictions)\n",
    "    top_percent = int(top_frac * len(predictions))\n",
    "    # Calculate uncertainties as the top confidence of each prediction\n",
    "    uncertainties, top_indices = predictions.max(-1)[0].topk(top_percent, largest=False)\n",
    "    print(f\"Adding {len(top_indices)} images to training set for Active Learning.\")\n",
    "    # Pass both top_indices and uncertainties to transfer_unlabelled_to_labelled\n",
    "    train_dataset, unlabelled_dataset = transfer_unlabelled_to_labelled(unlabelled_dataset, train_dataset, top_indices, uncertainties)\n",
    "    visualize_decision_boundaries(model, unlabelled_dataset, device)\n",
    "    return train_dataset, unlabelled_dataset\n",
    "\n",
    "def random_sampling_iteration(unlabelled_dataset, sample_size):\n",
    "    random_indices = torch.randperm(len(unlabelled_dataset))[:sample_size]\n",
    "    print(f\"Adding {len(random_indices)} images to training set for Random Sampling.\")\n",
    "    return random_indices\n",
    "\n",
    "\n",
    "# Active Learning Loop\n",
    "datapoint_list = []  # To store the number of labeled datapoints for active learning\n",
    "accuracy_list = []  # To store accuracy after each iteration of active learning\n",
    "for i in range(label_iterations):\n",
    "    description = f\"Active Learning Iteration {i + 1}\"\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    model.load_state_dict(model_parameters)  # Reset model parameters before training\n",
    "    # Train model and save accuracies\n",
    "    accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, val_interval=10, description=description)\n",
    "    datapoint_list.append(len(train_dataset))\n",
    "    accuracy_list.append(accuracies)\n",
    "    if i < label_iterations - 1:\n",
    "        train_dataset, unlabelled_dataset = label_iteration(model, train_dataset, unlabelled_dataset, device, top_frac=top_frac)\n",
    "        print(f\"After AL iteration {i + 1}:\")\n",
    "        print(f\" - Labeled images in training set: {len(train_dataset)}\")\n",
    "        print(f\" - Remaining unlabeled images in unlabeled set: {len(unlabelled_dataset)}\")\n",
    "        visualize_decision_boundaries(model, unlabelled_dataset, device)  # Visualize decision boundaries after adding new samples\n",
    "\n",
    "# Baseline Model\n",
    "print(\"\\nRunning Baseline Model\")\n",
    "n_datapoints = len(train_dataset) - len(start_train_dataset)\n",
    "model.load_state_dict(model_parameters)  # Reset model parameters for baseline\n",
    "train_dataset.data = torch.cat([start_train_dataset.data, start_unlabelled_dataset.data[:n_datapoints]])\n",
    "train_dataset.targets = torch.cat([start_train_dataset.targets, start_unlabelled_dataset.targets[:n_datapoints]])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "print(\"Baseline model training:\")\n",
    "print(f\" - Labeled images in training set: {len(train_dataset)}\")\n",
    "print(f\" - Unlabeled images in unlabeled set: {len(unlabelled_dataset)}\")\n",
    "baseline_accuracy = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, val_interval=10, description=\"Baseline Model\")\n",
    "\n",
    "# Random Sampling Loop for Comparison\n",
    "random_datapoint_list = []  # Stores number of labeled data points over iterations for random sampling\n",
    "random_accuracy_list = []  # Stores accuracy at each iteration for random sampling\n",
    "random_train_dataset = deepcopy(start_train_dataset)\n",
    "random_unlabelled_dataset = deepcopy(start_unlabelled_dataset)\n",
    "for i in range(label_iterations):\n",
    "    description = f\"Random Sampling Iteration {i + 1}\"\n",
    "    train_loader = torch.utils.data.DataLoader(random_train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    model.load_state_dict(model_parameters)  # Reset model to initial state for fair comparison\n",
    "    # Train model and store accuracies for random sampling method\n",
    "    accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, val_interval=10, description=description)\n",
    "    random_datapoint_list.append(len(random_train_dataset))\n",
    "    random_accuracy_list.append(accuracies)\n",
    "    \n",
    "    # Perform random sampling to add new samples to the labeled dataset\n",
    "    if i < label_iterations - 1:\n",
    "        random_indices = random_sampling_iteration(random_unlabelled_dataset, int(top_frac * len(random_unlabelled_dataset)))\n",
    "        random_train_dataset, random_unlabelled_dataset = transfer_unlabelled_to_labelled(random_unlabelled_dataset, random_train_dataset, random_indices)\n",
    "        print(f\"After Random Sampling iteration {i + 1}:\")\n",
    "        print(f\" - Labeled images in training set: {len(random_train_dataset)}\")\n",
    "        print(f\" - Remaining unlabeled images in unlabeled set: {len(random_unlabelled_dataset)}\")\n",
    "        visualize_decision_boundaries(model, random_unlabelled_dataset, device)  # Visualize decision boundaries after adding random samples\n",
    "\n",
    "# Plotting the accuracy results for all three methods\n",
    "datapoints = np.array(datapoint_list)  # Data points for active learning\n",
    "accuracies = np.array(accuracy_list).max(-1)  # Max accuracy per iteration for active learning\n",
    "random_datapoints = np.array(random_datapoint_list)  # Data points for random sampling\n",
    "random_accuracies = np.array(random_accuracy_list).max(-1)  # Max accuracy per iteration for random sampling\n",
    "\n",
    "# Create a plot showing Active Learning, Random Sampling, and Baseline accuracies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(datapoints, accuracies, label='Active Learning Accuracy')\n",
    "plt.plot(random_datapoints, random_accuracies, label='Random Sampling Accuracy', linestyle='--')\n",
    "plt.hlines(max(baseline_accuracy), min(datapoints), max(datapoints), label='Baseline Accuracy', color='red')\n",
    "plt.xlabel('Datapoints')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
